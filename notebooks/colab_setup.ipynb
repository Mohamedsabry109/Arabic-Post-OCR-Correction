{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arabic OCR Correction — Colab Inference\n",
    "\n",
    "Run LLM inference for Arabic OCR correction on a Google Colab GPU.\n",
    "\n",
    "**Three-step workflow:**\n",
    "1. **Local** — `python pipelines/run_phase2.py --mode export` → upload `inference_input.jsonl` to Google Drive\n",
    "2. **Here** — run this notebook (output goes directly to Drive — survives disconnects)\n",
    "3. **Local** — download `corrections.jsonl` from Drive, then `python pipelines/run_phase2.py --mode analyze`\n",
    "\n",
    "**Before running:**\n",
    "- Upload `inference_input.jsonl` to `MyDrive/arabic-ocr/` in Google Drive\n",
    "- Set `REPO_URL` in Cell 2 to your GitHub repo\n",
    "- Select **Runtime → Change runtime type → GPU (T4)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 — Mount Drive and install dependencies\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!pip install transformers accelerate huggingface_hub pyyaml tqdm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 — Clone the project repo\n",
    "# For private repos: https://YOUR_TOKEN@github.com/USERNAME/Arabic-Post-OCR-Correction.git\n",
    "REPO_URL = \"https://github.com/YOUR_USERNAME/Arabic-Post-OCR-Correction.git\"\n",
    "PROJECT_DIR = \"/content/project\"\n",
    "\n",
    "!git clone {REPO_URL} {PROJECT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 — Run inference (output to Drive — resumes automatically on reconnect)\n",
    "DRIVE_DIR = \"/content/drive/MyDrive/arabic-ocr\"\n",
    "\n",
    "!python {PROJECT_DIR}/scripts/infer.py \\\n",
    "    --input  {DRIVE_DIR}/inference_input.jsonl \\\n",
    "    --output {DRIVE_DIR}/corrections.jsonl \\\n",
    "    --model  Qwen/Qwen3-4B-Instruct-2507"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 — (Optional) Add HF sync as a backup in addition to Drive\n",
    "# import os\n",
    "# HF_REPO  = \"YOUR_HF_USERNAME/arabic-ocr-corrections\"\n",
    "# HF_TOKEN = \"hf_xxx\"  # or use: os.environ.get(\"HF_TOKEN\", \"\")\n",
    "#\n",
    "# !python {PROJECT_DIR}/scripts/infer.py \\\n",
    "#     --input  {DRIVE_DIR}/inference_input.jsonl \\\n",
    "#     --output {DRIVE_DIR}/corrections.jsonl \\\n",
    "#     --model  Qwen/Qwen3-4B-Instruct-2507 \\\n",
    "#     --hf-repo  {HF_REPO} \\\n",
    "#     --hf-token {HF_TOKEN} \\\n",
    "#     --sync-every 50"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

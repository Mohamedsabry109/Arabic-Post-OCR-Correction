{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arabic OCR Correction — Kaggle Inference\n",
    "\n",
    "Run LLM inference for Arabic OCR correction on a Kaggle GPU kernel.\n",
    "\n",
    "**Three-step workflow:**\n",
    "1. **Local** — `python pipelines/run_phase2.py --mode export` → upload `inference_input.jsonl` to a Kaggle dataset\n",
    "2. **Here** — run this notebook (resumes automatically on session timeout)\n",
    "3. **Local** — `python pipelines/run_phase2.py --mode analyze`\n",
    "\n",
    "**Before running:**\n",
    "- Set `REPO_URL` in Cell 2 to your GitHub repo\n",
    "- Set `HF_REPO` in Cell 3 to your HuggingFace dataset repo (for cross-session sync)\n",
    "- Add `HF_TOKEN` as a Kaggle secret (Add-ons → Secrets) — or paste it directly (not recommended)\n",
    "- Enable **GPU T4 x2** accelerator and **Internet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 — Install dependencies\n",
    "!pip install transformers accelerate huggingface_hub pyyaml tqdm -q\n",
    "# Uncomment for 4-bit quantization (needed on P100 or low-VRAM T4):\n",
    "# !pip install bitsandbytes -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 — Clone the project repo\n",
    "# For private repos: https://YOUR_TOKEN@github.com/USERNAME/Arabic-Post-OCR-Correction.git\n",
    "REPO_URL = \"https://github.com/YOUR_USERNAME/Arabic-Post-OCR-Correction.git\"\n",
    "PROJECT_DIR = \"/kaggle/working/project\"\n",
    "\n",
    "!git clone {REPO_URL} {PROJECT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 — Run inference\n",
    "# HF sync keeps progress safe across session timeouts — re-run this cell to resume.\n",
    "import os\n",
    "HF_REPO  = \"YOUR_HF_USERNAME/arabic-ocr-corrections\"  # HuggingFace dataset repo\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\", \"\")             # Read from Kaggle secret\n",
    "\n",
    "# Adjust --input to match your Kaggle dataset name\n",
    "!python {PROJECT_DIR}/scripts/infer.py \\\n",
    "    --input  /kaggle/input/YOUR_DATASET_NAME/inference_input.jsonl \\\n",
    "    --output /kaggle/working/corrections.jsonl \\\n",
    "    --model  Qwen/Qwen3-4B-Instruct-2507 \\\n",
    "    --hf-repo  {HF_REPO} \\\n",
    "    --hf-token {HF_TOKEN} \\\n",
    "    --sync-every 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 — (Optional) Run a quick smoke test first (50 samples from KHATT-train)\n",
    "# !python {PROJECT_DIR}/scripts/infer.py \\\n",
    "#     --input  /kaggle/input/YOUR_DATASET_NAME/inference_input.jsonl \\\n",
    "#     --output /kaggle/working/corrections_test.jsonl \\\n",
    "#     --model  Qwen/Qwen3-4B-Instruct-2507 \\\n",
    "#     --datasets KHATT-train --limit 50"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
